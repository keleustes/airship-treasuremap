apiVersion: armada.airshipit.org/v1alpha1
kind: ArmadaChart
metadata:
  labels:
    hosttype: fluentd
    name: fluentd
  name: fluentd
  namespace: osh-infra
spec:
  chart_name: fluentd
  dependencies:
  - osh-infra-helm-toolkit
  install:
    no_hooks: false
  release: fluentd
  source:
    location: https://opendev.org/openstack/openstack-helm-infra
    reference: 29fc716cf3ff636a66944903fbbe9bd3f921e22f
    subpath: fluentd
    type: git
  upgrade:
    no_hooks: false
    post:
      create: []
    pre:
      create: []
      delete:
      - labels:
          release_group: airship-fluentd
        type: job
  values:
    conf:
      fluentd:
        template: |
          <source>
            bind 0.0.0.0
            port 24220
            @type monitor_agent
          </source>

          <source>
            bind 0.0.0.0
            port "#{ENV['FLUENTD_PORT']}"
            @type forward
          </source>

          <match fluent.**>
            @type null
          </match>

          <match kube.var.log.containers.**.log>
            <rule>
              key log
              pattern /info/i
              tag info.${tag}
            </rule>
            <rule>
              key log
              pattern /warn/i
              tag warn.${tag}
            </rule>
            <rule>
              key log
              pattern /error/i
              tag error.${tag}
            </rule>
            <rule>
              key log
              pattern /critical/i
              tag critical.${tag}
            </rule>
            <rule>
              key log
              pattern (.+)
              tag info.${tag}
            </rule>
            @type rewrite_tag_filter
          </match>

          <filter **.kube.var.log.containers.**.log>
            enable_ruby true
            <record>
              application ${record["kubernetes"]["labels"]["application"]}
              level ${tag_parts[0]}
            </record>
            @type record_transformer
          </filter>

          <filter openstack.**>
            <record>
              application ${tag_parts[1]}
            </record>
            @type record_transformer
          </filter>

          <match openstack.**>
            <rule>
              key level
              pattern INFO
              tag info.${tag}
            </rule>
            <rule>
              key level
              pattern WARN
              tag warn.${tag}
            </rule>
            <rule>
              key level
              pattern ERROR
              tag error.${tag}
            </rule>
            <rule>
              key level
              pattern CRITICAL
              tag critical.${tag}
            </rule>
            @type rewrite_tag_filter
          </match>

          <match *.openstack.**>
            <rule>
              key application
              pattern keystone
              tag auth.${tag}
            </rule>
            <rule>
              key application
              pattern horizon
              tag auth.${tag}
            </rule>
            <rule>
              key application
              pattern mariadb
              tag auth.${tag}
            </rule>
            <rule>
              key application
              pattern memcached
              tag auth.${tag}
            </rule>
            <rule>
              key application
              pattern rabbitmq
              tag auth.${tag}
            </rule>
            @type rewrite_tag_filter
          </match>

          <match libvirt>
            <buffer>
              chunk_limit_size 8MB
              flush_interval 15s
              flush_thread_count 8
              queue_limit_length 256
              retry_forever false
              retry_max_interval 30
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            reload_connections false
            reconnect_on_error true
            reload_on_failure true
            include_tag_key true
            logstash_format true
            logstash_prefix libvirt
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match qemu>
            <buffer>
              chunk_limit_size 8MB
              flush_interval 15s
              flush_thread_count 8
              queue_limit_length 256
              retry_forever false
              retry_max_interval 30
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            reload_connections false
            reconnect_on_error true
            reload_on_failure true
            include_tag_key true
            logstash_format true
            logstash_prefix qemu
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match journal.**>
            <buffer>
              chunk_limit_size 8MB
              flush_interval 15s
              flush_thread_count 8
              queue_limit_length 256
              retry_forever false
              retry_max_interval 30
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            reload_connections false
            reconnect_on_error true
            reload_on_failure true
            include_tag_key true
            logstash_format true
            logstash_prefix journal
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match kernel>
            <buffer>
              chunk_limit_size 8MB
              flush_interval 15s
              flush_thread_count 8
              queue_limit_length 256
              retry_forever false
              retry_max_interval 30
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            reload_connections false
            reconnect_on_error true
            reload_on_failure true
            include_tag_key true
            logstash_format true
            logstash_prefix kernel
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match **>
            <buffer>
              chunk_limit_size 8MB
              flush_interval 15s
              flush_thread_count 8
              queue_limit_length 256
              retry_forever false
              retry_max_interval 30
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            reload_connections false
            reconnect_on_error true
            reload_on_failure true
            include_tag_key true
            logstash_format true
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            @type elasticsearch
            type_name fluent
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match *ceph-**.log>
            <buffer>
              chunk_limit_size 8MB
              flush_interval 15s
              flush_thread_count 8
              queue_limit_length 256
              retry_forever false
              retry_max_interval 30
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            reload_connections false
            reconnect_on_error true
            reload_on_failure true
            include_tag_key true
            logstash_format true
            logstash_prefix ceph
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>
    endpoints:
      elasticsearch:
        auth:
          admin:
            password: password123
            username: elasticsearch
      fluentd:
        host_fqdn_override:
          default: ""
        hosts:
          default: fluentd-logging
        name: fluentd
        namespace: osh-infra
        path:
          default: ""
        port:
          metrics:
            default: 24220
          service:
            default: 24224
        scheme:
          default: http
      prometheus_fluentd_exporter:
        host_fqdn_override:
          default: ""
        hosts:
          default: fluentd-exporter
        namespace: osh-infra
        path:
          default: /metrics
        port:
          metrics:
            default: 9309
        scheme:
          default: http
    images:
      tags: {}
    labels:
      fluentd:
        node_selector_key: fluentd
        node_selector_value: enabled
      job:
        node_selector_key: openstack-control-plane
        node_selector_value: enabled
      prometheus_fluentd_exporter:
        node_selector_key: openstack-control-plane
        node_selector_value: enabled
    monitoring:
      prometheus:
        enabled: true
    pod:
      replicas:
        fluentd: 1
      resources:
        fluentd:
          limits:
            cpu: 2000m
            memory: 4Gi
          requests:
            cpu: 1000m
            memory: 2Gi
        jobs:
          image_repo_sync:
            limits:
              cpu: 2000m
              memory: 1024Mi
            requests:
              cpu: "0"
              memory: "0"
          tests:
            limits:
              cpu: 2000m
              memory: 1024Mi
            requests:
              cpu: "0"
              memory: "0"
        prometheus_fluentd_exporter:
          limits:
            cpu: 2000m
            memory: 1024Mi
          requests:
            cpu: "0"
            memory: "0"
  wait:
    labels:
      release_group: airship-fluentd
    timeout: 900
